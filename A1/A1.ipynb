{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greatest-foster",
   "metadata": {},
   "source": [
    "# Machine Learning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-saying",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-investment",
   "metadata": {},
   "source": [
    "# Name: Shivam Verma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-representative",
   "metadata": {},
   "source": [
    "# Email address: shivam.59910103@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-baking",
   "metadata": {},
   "source": [
    "# Step 1: Parameter Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-worcester",
   "metadata": {},
   "source": [
    "If we are given a data set, we identify one quantity in a column of dataset as s.t. the feature variable ($x^{i}$), and  another as the target variable ($y^{i}$), alongwith the offset/error/unmodelled effects/residuals  ($\\varepsilon^{i}$) which tells us the error caused by a given value of $\\theta$ we choose for the best fit of the curve with the dataset given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-trunk",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "y^{i} = \\theta^{T} x^{i} + \\varepsilon^{i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-heavy",
   "metadata": {},
   "source": [
    "# Step 2: Assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-blake",
   "metadata": {},
   "source": [
    "We assume that the residuals follow a gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-porter",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "i.e. P(\\theta)=\\frac{1}{\\sqrt{2\\pi \\sigma}} \\exp \\left[-\\frac{\\theta^{2}}{2\\sigma^{2}}\\right]\n",
    "\\end{equation}\n",
    " where, $\\sigma$ is the variance of the dataset.\n",
    "now, we can write,\n",
    "\\begin{equation}\n",
    "P(y^{i}|x^{i};\\theta)=\\frac{1}{\\sqrt{2\\pi \\sigma}} \\exp \\left[-\\frac{\\left(y^{i}-\\theta^{T} x^{i}\\right)^{2}}{2\\sigma^{2}}\\right]\n",
    "\\end{equation}\n",
    "Above equation tells us the probablity of the target value  $y^{i}$ for a given feature $x^{i}$ and residual $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-anger",
   "metadata": {},
   "source": [
    "# Step 3: Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-atmosphere",
   "metadata": {},
   "source": [
    "We can define a new function that tells us about the \"likelihood\" of the Gaussian Distribution we obtained above. we can write it as,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-addiction",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L(\\theta)=\\prod \\limits_{i=1}^{n} P(y^{i}|x^{i};\\theta)=\\prod \\limits_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi \\sigma}} \\exp \\left[-\\frac{\\left(y^{i}-\\theta^{T} x^{i}\\right)^{2}}{2\\sigma^{2}}\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-vietnamese",
   "metadata": {},
   "source": [
    "Taking Log of above equation, we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-surge",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "l(\\theta)=\\ln\\left[L(\\theta)\\right]=\\underbrace{n\\ln\\left(\\frac{1}{\\sqrt{2\\pi \\sigma}}\\right)}_{{\\textrm{constant}}}-\\frac{1}{\\sigma^{2}}\\sum\\limits_{i=1}^{n}\\underbrace{\\frac{1}{2}\\left(y^{i}-\\theta^{T} x^{i} \\right)^{2}}_{ls(\\theta)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-relief",
   "metadata": {},
   "source": [
    "Our aim is to maximum the function $l(\\theta)$ also referred to as \"log likelihood\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-florist",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "ls(\\theta)= \\frac{1}{2}\\left(y^{i}-\\theta^{T} x^{i} \\right)^{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-object",
   "metadata": {},
   "source": [
    "We can clearly see in the above equation that to maximize the log likelihood we need to minimize $ls(\\theta)$, and to minimize $ls(\\theta)$ we have to differentiate it and find it's minima. which is nothing but least square criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-engine",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-subscription",
   "metadata": {},
   "source": [
    "We started with a dataset where we first identified the elemts of it into a more familiar nomenclature to understand it's role. Upon the assumption of Gaussian distribution of the residuals, we arrive at the notion of likelihood which we intend to maximize in order to get the curve we intend to fit our data with is as close as possible. Doing so, we end up minimizing the function $ls(\\theta)$ which we end up realizing is least squaring criterion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-direction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
